<!DOCTYPE html>
    <html>
      <head>
        <meta charset="utf-8" />
        <meta content="IE=edge" http-equiv="X-UA-Compatible" />
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <meta content="width=device-width, initial-scale=1, maximum-scale=1" name="viewport" />
        <title>Unstructured data (text) process</title>

        <style>
          html {
            margin: 0;
            padding: 0;
          }

          @font-face {
  font-family: 'mm-iconfont';
  src: url('data:application/font-woff2;charset=utf-8;base64,d09GMgABAAAAAAVcAA0AAAAADSAAAAUHAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP0ZGVE0cGh4GVgCCShEICo0IigYLGAABNgIkAx4EIAWFLAd0G58KyI7S1LBNkiTFr/P/+6Z638ziLBkIQ8wrsxwEKUmBA4Dwlfarxzy8f+PP7b21ZXFa6IFleXg1a60AqO3LF3jX79fq2xMRxM/jDd1CpYX3FxcP1SqJuY6YNU3FUiQ2jtU11Up8H/EkAATA3TXpGgA83rt/vfLZBDABYQCGcAKRAAxAFXRBBnayKwD+gZ+nPyqFBjBygXL/DlvTIWjwo3cVuK8s9Sl++AEEEjlOjElBk3hilJIMpUKKY21LyxouyaqeWOQjuRrUI+IKdQAY7d9DwI5a04k3MIQFzgG2AOwIKjVqJIrYTsbHABOn6EE+VdOSA1gHO0CS9GBxkMQUvqKqmhP23oxVltyoYu+7Facuv129xJ6zAUpuNJw/Noer8zbl/7HRtyFEqCv9mw2LZ3VXCfF7ULGQwXk1E0zFkant5pHX+SO069xIZQFP7GuSunhzT+uPuaGY8wjz93lhNH9+VyPuCPieEDFvrGZaKEn8By0/Xn3v0RVHUmC89ZOhDlh3jGjeou4WwZ4VRP5wFNIcni96pNDC/qa/zwFLw/qDuH+eGGTtvRnLltyoYu67FceX3+5qwVyZ4I0Xa9BhhYiSnsziTU5ZezSSLTiSYq47FsUXHwcvFjNkwu3NBXzMKiJ/15BtsMQ1xgy5e7/7/fvd7t3pcudO16737nWjDd3v3u16ULnTY0/s1yP0/Scmui+Y0HDii4p2hF3JmehUsiKsiv/3cSrHVX6R/IJJdzYQ9r9pP26TdOc/zP6LnbKg9ZkfiIwv+XOzYQe94qkIvdk05Kn/lyMsmm8KPh98KGQVX3h25WBxRS+vXRVyjG6mfDgvpohyqM+M8zOu6OX0K63v9aXZ8EOl+hM99FbLkGeTpl4Nig85BNS98ahbdCwAz502byvV8h3Wg/UjvlpDaulHWXJ45xmpkR+vfH/c0lR+U6qRDFPFMasTvr+qVeUxFMVUJpGYeohQqEP2nPx5SKO4ooVwruVuCjlnklU9Hy5kSay6LNeiYqv7PjU71+oQWCgHdmB+QcB1t5V7+623sbeXXsGLgy+EbAxegxZ1XtyouW5Ld5F9q9GtCZ11Z2HDJg27dS5c0djIMyrvwL1Elbgmbkv3nTmpbTx5a58ZEeHlIiJmhEeUCw87OCNCZSJMkqK4nWJa+E70KviUNnlpz8pnolu0atLWPDd5Ye+6N0Latm/RSb7VtNuTc6v4gwfcUq568CBa6AgAAAnf3mlYOr2/U+eHZkg41F2gtCyzuA+AhmkRcXiKqLkGv0G0LKl6EWquoiXD9ua35Kvrb/DSahlAIBNQhmOQZyAoDJUTmoihl4lRjTZxhnkgcQ+BzH1GFGkwk5AdnosNwXEIHFUdQBaAiYRpZGJsHhMXZjJI3FUgc8+Bwv1kErqFfbIhLWZBaGw410AjbdshEgwyzrnAYKW8POuMJEDcicMjIvxjg+tAiRK5pAole26Fi4FOXHlGKTbQcPjt4uTbTV5w7sY13AgFgxNUVE4FuIWzBBXLVegDmsd7+xlrL3oZYbQ8lXKUI3lyPYaTxhIJmrG5rmK9vlSCoflfKeQabKRy8CCw7YjReZVGjvRc/8Gn3vEiLOr74PlAfv+1Q9VSHs/l6Tm/nMFjJuLiPNHTGI9vR5xALUQwYDyIsGDESSKZFFJJI908y2iXWzJq0Cj5RDdOO6nFE954+YIpXx1UcFoaLx+TN/EhpYPVt1cBAA==') format('woff2'),
      url('data:application/font-woff;charset=utf-8;base64,d09GRgABAAAAAAfMAA0AAAAADSAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABGRlRNAAAHsAAAABoAAAAcjQ+WV0dERUYAAAeQAAAAHgAAAB4AKQART1MvMgAAAaAAAABCAAAAVjxwSCNjbWFwAAAB/AAAAEkAAAFK5m7pl2dhc3AAAAeIAAAACAAAAAj//wADZ2x5ZgAAAmAAAAN8AAAGiB3BA0toZWFkAAABMAAAADAAAAA2GiKzS2hoZWEAAAFgAAAAHQAAACQHcAOFaG10eAAAAeQAAAAYAAAAHg2lAQZsb2NhAAACSAAAABgAAAAYB5YI6G1heHAAAAGAAAAAHwAAACABHQB6bmFtZQAABdwAAAFNAAACrJtyy2Nwb3N0AAAHLAAAAFkAAAB0hhp62HjaY2BkYGAA4iTORQfi+W2+MnCzMIDA7a3bl8Nptv8NzJOYG4BcDgYmkCgASEMMAXjaY2BkYGBu+N/AEMPCAALMkxgYGVABCwBRzAL+AAAAeNpjYGRgYOBmyGPgYAABJiDmAkIGhv9gPgMAFOkBmAB42mNgZGFgnMDAysDA1Ml0hoGBoR9CM75mMGLkAIoysDIzYAUBaa4pDA7PGJ8ZMDf8b2CIYW5kaAQKM4LkAN52DA4AAHjaY2GAABYIZmPwBMI8MPRkaAAAEskCuHjaY2BgYGaAYBkGRgYQcAHyGMF8FgYNIM0GpBkZmJ4xPjP4/5+BAUhr/f8vxSR5C6oeCBjZGOAcRiYgwcSAChgZhj0AAM5gCc8AAAAAAAAAAAAAAACYAPQBjgH2Al4CugMSA0R42o1UT2zTdhR+z26c2ooduXbiEIdkjhtnKzRMThuXqI34syKlaDBp1ZD2hwMMkJAojAPigKAwDrtsmjggDcSFcoALEtzWy05rx20r5VAEhx2oYOyI2CVxeT+7JU0h0RTne9/zTy953/f8DL0grFzjv+DPQhxysAU82A374Ss4BoBZNFQFo1YJi2oNvYilYELVk2XLrXhqCdFN6kLULuFQhW61uMf4Fsw7xO11vNDhPvfv4Cji6GDzchi5c83LcV2Pc+fiOqLucyyxGeBthq/fwn8MfmTQ3zrecJM/iyMDjecDI0iRT1HchX1K47miaQqfUvqaM3qW/U1WX4uLIQ+vtgQAeqC+Ms1P8dPQC2kYgCr5ZKmWaued4YLl5jDJPLMtSskzjXwxEmFeHK6hUXaTmzF0iuXcT36C+25KUpr/cOO6cimGaGrN7VoG03N4WJIRZcm/EcZ5SQ6AOG83ZrlfFWlB+UHWGs9009T5m3raPyhL20SFQJJfyFIprKNAfQttfY/Bp/ANnHindxqvEPY+VNFo5Fmk+SfKWQybTqxrfwxL6FlhzkrGaPRGkIdyW3nrnOTq3OmTIpNb15XzciYQmzmDW/P0lBVyVTEWE6shpm05/gRjgigK/quoKEYZx951yepB4MasLD6Mf6/0Nf5edcP0B/PbED/eMSi4GBM1UcZvFQpksbPphfzBhCRUBCmAW2J0WOgVo+WoyCj7eQLm2RR5dmXVsw9hBEZhR8uz4ns8ywuU0jZQ4tgFq32DDCtheaqtcvdp6qdP0niaL8kH+bxs6s0q9f2Y4yNYjfCcP4dVx6UNc/y5IKp4xL++uLuT1KNU8iASQY/jJ1nRg7AYPcf9c2LZv4JTAO16TPgIttNzsLOrnvL/EJSwh98VlNaaI7qZ1v7oruj6rg2KtExa429pmW6KrtbjCwsb9aQhCyVwodJ9PnTyPhHs03Eqj/AT/w4eNwuI/Rn/ahBzrHv27TgR/zfcOckKfsn0s0I8ZhbG68t16jvStosOdV3rvomWS1tEGe2QsZ6XGae3KPFOq3UXf06l/FOGsRbvsatT1zNGKZUqGbP0JbYagIdpAH6aZ47LsAlAxGTFq2HREaIK5uhFUAzeFYaC3Ev/4pe/18flC1//ta8u7Hk6s9TTszQTIFf0Dw1l9u6bv1ZLfPb5wwPzaweEbwCNs0tEeNqNkT9OwzAYxZ/7D9FIHUAwe2IAmv4ZO1Kp7Awd2NrUCa2SOHLcSl04BAMH4Bg9AMfgAD0Fr+HrUpbGyqefn5/fl9gArvADhb/nBo/CCgFehWu4wEa4Tv1TuEHeCTfJx5wWAlUTbuNBxcIBrtWOCapxydl9lXZghVs8CdfQQSxcp/4u3CB/CTfJ38It8l64janqCAe4Ux9UxnAwmMGzLqAxx5Z1iQgWOTsdqqcP7bEzM28Wer7Vy8jmsc095Yyj+8+PLOseTcALsxOskbKP49Qk63Tmztt7jmfKfIeSrsOqxgAh+pSNK5c214Owf17OM3PyKuv0PEreb4IhVc+9mq9jQkaaSJLh36VkjaJaW1GJqIeMNblxx6MrN8nQ+1jHzmZ6wrYmTa0unF2ZyNP8VvUoMEKPIz5JD6vvz2jzvhj1erEEhJHN8AuKq3jTAAAAeNpdiEsOgCAQxXgogp+reChxJnESgUTQ86u4s4smrdLqY6iG+jPWq6HRoIVBBwuHfgoci6Q4h9Ofhg652AWJFFNhkzfmYr2Uxe9P7ULcUFotSX7PDa0DFeMAAAAAAAAB//8AAgABAAAADAAAABYAAAACAAEAAwAKAAEABAAAAAIAAAAAeNpjYGBgZACCq0vUOUD07a3bl8NoAEb7B4YAAA==') format('woff');
  font-weight: normal;
  font-style: normal;
  font-display: swap;
}

.mm-iconfont::before {
  font-family: 'mm-iconfont', sans-serif !important;
  font-size: 16px;
  font-style: normal;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

          .mention[data-type='1']::before,
          .mention[data-type='3']::before,
          .mention[data-type='8']::before,
          .mention[data-type='11']::before,
          .mention[data-type='12']::before,
          .mention[data-type='15']::before,
          .mention[data-type='16']::before {
            content: '\e62f';
            display: inline-block;
            vertical-align: middle;
            margin-top: -4px;
            font-size: inherit;
          }
          .mention[data-type='3']::before {
            content: '\e62c';
          }
          .mention[data-type='8']::before {
            content: '\e62d';
          }
          .mention[data-type='11']::before {
            content: '\e62b';
          }
          .mention[data-type='12']::before {
            content: '\e62a';
          }
          .mention[data-type='15']::before {
            content: '\e62e';
          }
          .mention[data-type='22']::before {
            content: '\e602';
          }

          body {
            margin: 50px 20px;
            padding: 0;
            color: #333;
            font-family: 'Source Sans Pro', -apple-system, BlinkMacSystemFont, 'PingFang SC',
                  Helvetica, Arial, 'Microsoft YaHei', 微软雅黑, 黑体, Heiti, sans-serif,
                  SimSun, 宋体, serif,
                  'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
          }

          body.narrow {
            max-width: 790px;
            margin-left: auto;
            margin-right: auto;
            padding-left: 20px;
            padding-right: 20px;
          }

          .title {
            min-height: 40px;
            padding-left: 10px;
            padding-bottom: 24px;
            margin-bottom: 20px;
            line-height: 40px;
            font-size: 26px;
            font-weight: 500;
            border-bottom: 1px solid #e5e6e8;
          }

          .node-list {
            margin: 0 0 0 28px;
            padding: 0;
            list-style: none;
          }

          .node {
            position: relative;
          }

          .node.drill-node > .content {
            margin-bottom: 15px;
            font-size: 20px;
            line-height: 28px;
          }

          .node.drill-node > .note {
            margin-bottom: 10px;
          }

          .content {
            min-height: 24px;
            padding-top: 2px;
            padding-bottom: 3px;
            line-height: 24px;
            font-size: 16px;
          }

          .note {
            position: relative;
            padding-bottom: 2px;
            line-height: 22px;
            font-size: 14px;
            color: #888;
            white-space: pre-wrap;
          }

          .content > *,
          .note > * {
            padding-top: 2px;
            padding-bottom: 2px;
          }

          .note:empty {
            padding-bottom: 0;
          }

          .node.finished .content,
          .node.finished .note {
            opacity: 0.5;
          }

          .node.finished > .content {
            text-decoration: line-through;
          }

          .heading1 > .content {
            min-height: 34px;
            line-height: 34px;
            font-size: 24px;
            font-weight: 500;
          }

          .heading2 > .content {
            min-height: 30px;
            line-height: 30px;
            font-size: 21px;
            font-weight: 500;
          }

          .heading3 > .content {
            min-height: 27px;
            line-height: 27px;
            font-size: 19px;
            font-weight: 500;
          }

          .mention {
            padding-left: 2px;
            padding-right: 2px;
            color: #5856d5;
            word-break: break-all;
            text-decoration: none;
          }

          .content-link {
            color: unset;
            opacity: 0.6;
            word-break: break-all;
          }

          .tag {
            text-decoration: underline;
            opacity: 0.6;
          }

          .bold {
            font-weight: bold;
          }

          .italic {
            font-style: italic;
          }

          .underline {
            text-decoration: underline;
          }

          .content .highlight-red,
          .highlight-red > .content > * {
            background-color: #fbbfbc;
          }

          .content .highlight-yellow,
          .highlight-yellow > .content > * {
            background-color: #f8e6ab;
          }

          .content .highlight-blue,
          .highlight-blue > .content > * {
            background-color: #bacefd;
          }

          .content .highlight-cyan,
          .highlight-cyan > .content > * {
            background-color: #a9efe6;
          }

          .content .highlight-pink,
          .highlight-pink > .content > * {
            background-color: #fdddef;
          }

          .content .highlight-olive,
          .highlight-olive > .content > * {
            background-color: #bbbfc4;
          }

          .content .highlight-grey,
          .highlight-grey > .content > * {
            background-color: #bbbfc4;
          }

          .text-color-red {
            color: #dc2d1e;
          }

          .text-color-yellow {
            color: #ffaf38;
          }

          .text-color-green {
            color: #75c940;
          }

          .text-color-blue {
            color: #3da8f5;
          }

          .text-color-purple {
            color: #797ec9;
          }

          .bullet {
            position: absolute;
            left: -25px;
            top: 5px;
            width: 18px;
            height: 18px;
            border-radius: 9px;
          }

          .node.collapsed > .bullet {
            background-color: #dee0e3;
          }

          .heading1 > .bullet {
            top: 10px;
          }

          .heading2 > .bullet {
            top: 8px;
          }

          .heading3 > .bullet {
            top: 6px;
          }

          .bullet-dot {
            position: absolute;
            left: 6px;
            top: 6px;
            width: 6px;
            height: 6px;
            background-color: rgb(100, 106, 115);
            border-radius: 3px;
          }

          .image-list {
            position: relative;
            margin: 0;
            padding: 0;
            list-style: none;
          }

          .image-item {
            padding-top: 2px;
            padding-bottom: 8px;
          }

          .image {
            display: block;
            max-width: 100%;
          }

          .children {
            position: relative;
          }

          .note::before,
          .image-list::before,
          .children::before {
            content: "";
            position: absolute;
            top: 0;
            left: -17px;
            width: 1px;
            height: 100%;
            background-color: #dee0e3;
          }

          .node.drill-node > .note::before,
          .node.drill-node > .image-list::before,
          .node.drill-node > .children::before,
          body.noline .note::before,
          body.noline .image-list::before,
          body.noline .children::before {
            display: none;
          }

          .node.drill-node > .note,
          .node.drill-node > .content,
          .node.drill-node > .image-list,
          .node.drill-node > .children {
            margin-left: 10px;
          }

          body.noline .node-list {
            margin-right: 20px;
          }

          .publish {
            margin-top: 20px;
            text-align: center;
            font-size: 13px;
            color: #666;
          }

          .publish-link {
            color: #4694FF;
          }

          .node .mention.mm-iconfont::before {
            content: '\e601';
          }

          .node .mention.mm-iconfont {
             color: #5856d5;
          }

          @media print {
            body {
              margin-top: 0;
              margin-bottom: 0;
            }
          }

          @page {
            margin-left: 0.25in;
            margin-right: 0.25in;
            margin-top: 0.5in;
            margin-bottom: 0.5in;
          }
        </style>
      </head>
      <body >
        <div class="title">Unstructured data (text) process</div>
        <ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>text is typically represented as a numerical vector using three steps: text normalization, tokenization, and tokens to IDs </span></div>
    <ul class="image-list">
    <li class="image-item">
    <img
      src="https://api2.mubu.com/v3/document_image/35b79d4e-e152-4b93-bab9-ebd4fbbd572f-14504445.jpg"
      style="width: 365px;"
      crossorigin="anonymous"
      class="image"
    />
  </li>
  </ul>
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">Text normalization</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Text normalization - also known as text cleanup - ensures words and sentences are consistent. For example, the same word may be spelled slightly differently; as in "dog", "dogs", and "DOG!" all refer to the same thing but are spelled in different ways. The same is true for sentences. Take these two sentences, for example:</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>"A person walking with his dog in Montréal !"</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>"a person walks with his dog, in Montreal."</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Both sentences mean the same, but have differing punctuation and verb forms. Here are some typical methods for text normalization:</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Lowercasing: make all letters lowercase, as this does not change the meaning of words or sentences</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Punctuation removal: remove punctuation from the text. Common punctuation marks are the period, comma, question mark, exclamation point, etc.</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Trim whitespaces: trim leading, trailing, and multiple whitespaces</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Normalization Form KD (NFKD) [3]: decompose combined graphemes into a combination of simple ones</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Strip accents: remove accent marks from words. For example: Màlaga →→ Malaga, Noël →→ Noel</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Lemmatization and stemming: identify a canonical representative for a set of related word forms. For example: walking, walks, walked →→ walk</span></div>
    
    
    
  </li>
  </ul></div>
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">Tokenization</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Tokenization is the process of breaking down a piece of text into smaller units called tokens. Generally, there are three types of tokenization:</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Word tokenization: split the text into individual words based on specific delimiters. For example, a phrase like "I have an interview tomorrow" becomes [ "I", "have", "an", "interview", "tomorrow"]</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Subword tokenization: split text into subwords (or n-gram characters)</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Character tokenization: split text into a set of characters </span></div>
    
    
    
  </li>
  </ul></div>
  </li>
  </ul></div>
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">Tokens to IDs</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Once we have the tokens, we need to convert them to numerical values (IDs). The representation of tokens with numerical values can be done in two ways:Convert tex</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Lookup table</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">Lookup table.</span><span> In this method, each unique token is mapped to an ID. Next, a lookup table is created to store these 1:1 mappings. Below Figure shows what the mapping table might look like.</span></div>
    <ul class="image-list">
    <li class="image-item">
    <img
      src="https://api2.mubu.com/v3/document_image/3c53c085-1bd2-4dfa-a2d1-7363f6171b09-14504445.jpg"
      style="width: 198px;"
      crossorigin="anonymous"
      class="image"
    />
  </li>
  </ul>
    
    
  </li>
  </ul></div>
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Hashing</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">Hashing.</span><span> Hashing, also called "feature hashing" or "hashing trick," is a memory-efficient method that uses a hash function to obtain IDs, without keeping a lookup table. </span></div>
    <ul class="image-list">
    <li class="image-item">
    <img
      src="https://api2.mubu.com/v3/document_image/69ba0b69-8711-45ad-ae62-54be96d1366d-14504445.jpg"
      style="width: 489px;"
      crossorigin="anonymous"
      class="image"
    />
  </li>
  </ul>
    
    
  </li>
  </ul></div>
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Comparison between lookup table VS hashing method</span></div>
    <ul class="image-list">
    <li class="image-item">
    <img
      src="https://api2.mubu.com/v3/document_image/0e6e88c1-4b77-47c0-8b52-6101878386b8-14504445.jpg"
      style="width: 766px;"
      crossorigin="anonymous"
      class="image"
    />
  </li>
  </ul>
    
    
  </li>
  </ul></div>
  </li>
  </ul></div>
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">Convert tokens to numeric embedding</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Statistical methods</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Those methods rely on statistics to convert a sentence into a feature vector. Two popular statistical methods are:</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Bag of Words (BoW)</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">BoW.</span><span> This method converts a sentence into a fixed-length vector. It models sentenceword occurrences by creating a matrix with rows representing sentences, and columns representing word indices. </span></div>
    <ul class="image-list">
    <li class="image-item">
    <img
      src="https://api2.mubu.com/v3/document_image/1c2b9575-5251-4255-a43b-02fba2620c9e-14504445.jpg"
      style="width: 729px;"
      crossorigin="anonymous"
      class="image"
    />
  </li>
  </ul>
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>BoW is a simple method that computes sentence representations fast, but has the following limitations:</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>It does not consider the order of words in a sentence. For example, "let's watch TV after work" and "let's work after watch TV" would have the same BoW representation.</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>The obtained representation does not capture the semantic and contextual meaning of the sentence. For example, two sentences with the same meaning but different words have a totally different representation.</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>The representation vector is sparse. The size of the representation vector is equal to the total number of unique tokens we have. This number is usually very large, so each sentence representation is mostly filled with zeros.</span></div>
    
    
    
  </li>
  </ul></div>
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Term Frequency Inverse Document Frequency (TF-IDF)</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">TF-IDF.</span><span> This is a numerical statistic intended to reflect how important a word is to a document in a collection or corpus. TF-IDF creates the same sentence-word matrix as in BoW, but it normalizes the matrix based on the frequency of words.</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Since TF-IDF gives less weight to frequent words, its representations are usually better than BoW. However, it has the following limitations:</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>A normalization step is needed to recompute term frequencies when a new sentence is added.</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>It does not consider the order of words in a sentence.</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>The obtained representation does not capture the semantic meaning of the sentence.</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>The representations are sparse.</span></div>
    
    
    
  </li>
  </ul></div>
  </li>
  </ul></div>
  </li>
  </ul></div>
  </li>
  </ul></div>
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">ML Based Models</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>In these methods, an ML model converts sentences into meaningful word embeddings so that the distance between two embeddings reflects the semantic similarity of the corresponding words. </span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>For example, if two words, such as "rich" and "wealth" are semantically similar, their embeddings are close in the embedding space. </span></div>
    <ul class="image-list">
    <li class="image-item">
    <img
      src="https://api2.mubu.com/v3/document_image/7f0f2c11-59d9-410b-be84-319d203f0881-14504445.jpg"
      style="width: 647px;"
      crossorigin="anonymous"
      class="image"
    />
  </li>
  </ul>
    
    
  </li>
  </ul></div>
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>There are three common ML-based approaches for transforming texts into embeddings:</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Embedding (lookup) layer</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">Embedding (lookup) layer</span><span> In this approach, an embedding layer is employed to map each ID to an embedding vector. </span></div>
    <ul class="image-list">
    <li class="image-item">
    <img
      src="https://api2.mubu.com/v3/document_image/16d97a5c-4d8e-433c-a162-e21626d4e007-14504445.jpg"
      style="width: 608px;"
      crossorigin="anonymous"
      class="image"
    />
  </li>
  </ul>
    
    
  </li>
  </ul></div>
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>Word2vec</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>These models use a shallow neural network architecture and utilize the co-occurrences of words in a local context to learn word embeddings. In particular, the model learns to predict a center word from its surrounding words during the training phase. After the training phase, the model is capable of converting words into meaningful embeddings.</span></div>
    
    
    
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>There are two main models based on word2vec: Continuous Bag of Words (CBOW)  and Skip-gram. Below it shows CBOW.</span></div>
    <ul class="image-list">
    <li class="image-item">
    <img
      src="https://api2.mubu.com/v3/document_image/b07c1c07-c6c2-4bdf-913a-db851e2705e1-14504445.jpg"
      style="width: 609px;"
      crossorigin="anonymous"
      class="image"
    />
  </li>
  </ul>
    
    
  </li>
  </ul></div>
  </li>
<li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span class="bold">Transformer-based architectures</span></div>
    
    
    <div class="children"><ul class="node-list">
    <li class="node heading1">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ><span>These models consider the context of the words in a sentence when converting them into embeddings. As opposed to word2vec models, they produce different embeddings for the same word depending on the context.</span></div>
    <ul class="image-list">
    <li class="image-item">
    <img
      src="https://api2.mubu.com/v3/document_image/fcbbeaf1-70d8-42f5-b455-0a75a6d5fcf8-14504445.jpg"
      style="width: 618px;"
      crossorigin="anonymous"
      class="image"
    />
  </li>
  </ul>
    
    
  </li>
  </ul></div>
  </li>
  </ul></div>
  </li>
<li class="node">
    <div class="bullet">
    <div class="bullet-dot"></div>
  </div>
    <div class="content mm-editor" ></div>
    
    
    
  </li>
  </ul></div>
  </li>
  </ul>
        <div class="publish">
        <span>以上内容整理于</span>
        <a target="_blank" class="publish-link" href="http://rhaegar://mubu.com?s=export-pdf">
          幕布文档
        </a>
      </div>
      </body>
    </html>
  